# Deployment Checklist

## ‚úÖ Implementation Complete

### Backend Created
- [x] FastAPI service with PaddleOCR (`backend/main.py`)
- [x] POST /ocr/extract endpoint
- [x] GET /health endpoint
- [x] Requirements.txt with dependencies
- [x] README with setup instructions

### Frontend Integration
- [x] Backend OCR client (`src/utils/backendOCR.js`)
- [x] Upload.jsx updated to use backend OCR
- [x] Environment variable support (VITE_BACKEND_URL)
- [x] Error handling for backend failures

### Documentation
- [x] PADDLEOCR_INTEGRATION.md (complete guide)
- [x] .env.example (environment variables)
- [x] Backend README.md (setup instructions)

### Git
- [x] All changes committed
- [x] Pushed to GitHub (commit d9da1a3)

---

## üöÄ Deployment Steps

### Step 1: Deploy Backend

#### Option A: Railway (Recommended)

```bash
cd backend
railway login
railway init
railway up
```

Get backend URL from Railway dashboard.

#### Option B: Render

1. Go to https://render.com
2. New ‚Üí Web Service
3. Connect GitHub repo: `codoncareai-oss/codoncareai_PATNA`
4. Settings:
   - Name: `codoncareai-backend`
   - Root Directory: `backend`
   - Build Command: `pip install -r requirements.txt`
   - Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`
   - Instance Type: At least 2GB RAM (for PaddleOCR)
5. Deploy

#### Option C: Fly.io

```bash
cd backend
fly auth login
fly launch --name codoncareai-backend
fly deploy
```

### Step 2: Update Frontend Environment

Update `.env` file:

```bash
VITE_GITHUB_TOKEN=your_github_token
VITE_BACKEND_URL=https://your-backend-url.railway.app
```

### Step 3: Deploy Frontend

```bash
vercel --prod
```

Or push to main branch (if auto-deploy is enabled).

Set environment variables in Vercel dashboard:
- `VITE_GITHUB_TOKEN`
- `VITE_BACKEND_URL`

### Step 4: Test

1. Open frontend URL
2. Upload a lab report (PDF or image)
3. Check browser console:
   - "üîß Calling backend OCR: filename.pdf"
   - "‚úÖ Backend OCR: X raw rows extracted"
   - "‚úÖ Phase 1 complete: X raw rows"
   - "‚úÖ Phase 2 complete: X normalized rows"
   - "‚úÖ ROW COUNT VERIFIED: X in = X out"

---

## üß™ Local Testing

### Terminal 1: Backend

```bash
cd backend
pip install -r requirements.txt
python main.py
```

Should see: `Uvicorn running on http://0.0.0.0:8000`

### Terminal 2: Frontend

```bash
npm run dev
```

Should see: `Local: http://localhost:5173`

### Test Backend Health

```bash
curl http://localhost:8000/health
```

Expected: `{"status":"ok","ocr":"paddleocr"}`

### Test OCR Extraction

```bash
curl -X POST http://localhost:8000/ocr/extract \
  -F "file=@path/to/test_report.pdf"
```

Expected: JSON with raw rows array

---

## üìä Architecture Verification

```
‚úÖ Frontend (React/Vite)
    ‚Üì
‚úÖ Backend (FastAPI + PaddleOCR)
    ‚Üì
‚úÖ Raw Rows (deterministic extraction)
    ‚Üì
‚úÖ LLM Normalizer (standardization only)
    ‚Üì
‚úÖ Normalized Rows (same count as raw rows)
```

---

## üîç Success Criteria

- [x] PaddleOCR installed as dependency (not forked)
- [x] Backend service created (FastAPI)
- [x] POST /ocr/extract endpoint working
- [x] One visible line = one raw row
- [x] No merging, no deletion, no inference
- [x] LLM NEVER used for extraction
- [x] LLM ONLY used for normalization
- [x] Row count preserved (Phase 1 ‚Üí Phase 2)
- [x] Frontend calls backend OCR first
- [x] Console logs show row counts
- [x] Hard fail on row count mismatch
- [x] All code committed and pushed

---

## üêõ Troubleshooting

### Backend not starting

Check Python version (3.8+):
```bash
python --version
```

Install dependencies:
```bash
pip install -r backend/requirements.txt
```

### Frontend can't reach backend

Check CORS in `backend/main.py`:
```python
allow_origins=["*"]  # Or specific frontend URL
```

Check environment variable:
```bash
echo $VITE_BACKEND_URL
```

### PaddleOCR errors

For CPU-only systems:
```bash
pip install paddlepaddle==2.6.0
```

For GPU systems:
```bash
pip install paddlepaddle-gpu==2.6.0
```

### Memory issues

PaddleOCR requires ~2GB RAM minimum.
Use at least 2GB instance on Railway/Render.

---

## üìù Next Steps

1. Deploy backend to Railway/Render/Fly.io
2. Update frontend environment variables
3. Deploy frontend to Vercel
4. Test with real lab reports
5. Monitor console logs for row count verification
6. Verify no data loss

---

## üéØ Key Principle

**LLM is NOT used for extraction.**
**LLM is ONLY used for normalization.**

PaddleOCR extracts ‚Üí LLM normalizes ‚Üí Zero data loss

---

## üì¶ Files Created/Modified

### Created:
- `backend/main.py` - FastAPI service with PaddleOCR
- `backend/requirements.txt` - Python dependencies
- `backend/README.md` - Backend documentation
- `src/utils/backendOCR.js` - Frontend OCR client
- `PADDLEOCR_INTEGRATION.md` - Complete integration guide

### Modified:
- `src/pages/Upload.jsx` - Use backend OCR
- `.env.example` - Add VITE_BACKEND_URL

### Commit:
- Hash: `d9da1a3`
- Branch: `main`
- Status: ‚úÖ PUSHED

---

## ‚úÖ Status: READY FOR DEPLOYMENT
